\documentclass[DIN, pagenumber=false, fontsize=11pt, parskip=half]{scrartcl}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage[utf8]{inputenc} % this is needed for umlauts
\usepackage[T1]{fontenc} 
\usepackage{commath}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{float}
\usepackage{tikz-timing}
\usepackage{tikz}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage{xstring}
\usepackage{circuitikz}
\usepackage{listings} % needed for the inclusion of source code
\usepackage[final]{pdfpages}
\usepackage{subcaption}
\usepackage{import}
\usepackage{cleveref}
\usepackage{bm}
\usepackage{tabularx}

\usetikzlibrary{calc,shapes.multipart,chains,arrows}

\newcommand{\Prb}[1]{P(\text{#1})}
\newcommand{\CPr}[2]{P(\text{#1}|\text{#2})}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator{\rank}{rank}
\newcommand{\R}[0]{\mathbb{R}}

%Inkscape fuckery
\newcommand{\incfig}[2][\columnwidth]{%
    \def\svgwidth{#1}
    \import{./}{#2.eps_tex}
}

\title{Pattern Recognition}
\author{Tim Luchterhand, Paul Nykiel, Jonas Strauch (Group P)}

\begin{document}
    \maketitle
    \section{Kernel Functions}
    \begin{enumerate}
        \item 
            \begin{equation*}
                \bm{\phi}(x) = \begin{pmatrix} x \\ {(x + 0.5)}^2 \end{pmatrix}
            \end{equation*}
            \setcounter{enumi}{3}
        \item
            \begin{enumerate}[label=\alph*)]
                \item
                    \begin{eqnarray*}
                        <\tilde{x}_i, \tilde{x}>
                            &=& x_i x + {(x_i + 0.5)}^2 {(x + 0.5)}^2 \\
                            &=& x_i x + {\left((x_i + 0.5) (x + 0.5)\right)}^2 \\
                            &=& x_i x + {(x_i x + 0.5 x_i + 0.5 x + 0.25)}^2 \\
                            &=& x_i x + {(x_i x + 0.5 x_i)}^2 
                                + 2 (x_i x + 0.5 x_i) (0.5 x + 0.25)
                                + {(0.5 x + 0.25)}^2 \\
                            &=& x_i x + x_i^2 x^2 + x_i^2 x + 0.25 x_i^2
                                + 2 (0.5 x_i x^2 + 0.25 x_i x + 0.5 x^2 x_i + 0.125 x_i) \\
                                && + 0.25 x^2 + 0.25 x + 0.0625 \\
                            &=& x_i x + x_i^2 x^2 + x_i^2 x + 0.25 x_i^2
                                + x_i x^2 + 0.5 x_i x + x^2 x_i + 0.25 x_i \\
                                && + 0.25 x^2 + 0.25 x + 0.0625 \\
                            &=& x_i^2 (x^2 + x + 0.25)
                                + x_i (x^2 + x + 0.5 x + x^2 + 0.25)
                                + 0.25 x^2 + 0.25 x + 0.0625 \\
                            &=& x_i^2 (x^2 + x + 0.25)
                                + x_i (2 x^2 + 1.5 x + 0.25)
                                + 0.25 x^2 + 0.25 x + 0.0625 \\
                            &=& k(x_i, x)
                    \end{eqnarray*}
            \end{enumerate}
            \setcounter{enumi}{5}
        \item
            \begin{eqnarray*}
                d(\tilde{x}, H) \norm{w}_2 &=& <w, \tilde{x}> + w_0 \\
                    &=& <w, \phi(x)> + w_0 \\
                    &\stackrel{\text{script p. 101}}{=}& <\sum_{i=1}^4 \alpha_i T_i \tilde{x_i}, \tilde{x}> + w_0 \\
                    &\stackrel{\text{linearity}}{=}& \sum_{i=1}^4 \alpha_i T_i <\tilde{x}_i, \tilde{x}> + w_0 \\
                    &\stackrel{\text{(2)}}{=}& \sum_{i=1}^4 \alpha_i T_i k(x_i,x) + w_0
            \end{eqnarray*}
        \item
            \begin{eqnarray*}
                \norm{w}_2 &=& \norm{\sum_{i=1}^4 \alpha_i T_i \tilde{x}_i}_2 \\
                    &=& \sqrt{<\sum_{i=1}^4 \alpha_i T_i \tilde{x}_i, \sum_{i=1}^4 \alpha_i T_i \tilde{x}_i>} \\
                    &\stackrel{\text{linearity}}{=}& \sqrt{\sum_{i=1}^4 \alpha_i T_i <\tilde{x}_i, \sum_{j=1}^4 \alpha_j T_j \tilde{x}_j>} \\
                    &\stackrel{\text{linearity}}{=}& \sqrt{\sum_{i=1}^4 \alpha_i T_i \sum_{j=1}^4 \alpha_j T_j <\tilde{x}_i, \tilde{x}_j>} \\
                    &=& \sqrt{\sum_{i=1}^4 \sum_{j=1}^4 T_i T_j \alpha_i \alpha_j <\tilde{x}_i, \tilde{x}_j>} \\
            \end{eqnarray*}
    \end{enumerate}


    \section{RBF Kernel}
    \begin{enumerate}
        \item
        Show that for $x_i, x_j \in \R$ it holds that $k(x_i, x_j) = \langle \bm{\phi}(x_i), \bm{\phi}(x_j) \rangle$
        with $k$ and $\bm{\phi}$ defined as in the exercise sheet.
        \begin{align*}
             &\langle \bm{\phi}(x_i), \bm{\phi}(x_j) \rangle = \\
             &e^{-\gamma x_i^2} e^{-\gamma x_j^2}
             \left( 1, \sqrt{\frac{2 \gamma}{1!}} x_i, \sqrt{\frac{(2 \gamma)^2}{2!}} x_i^2,
             \sqrt{\frac{(2 \gamma)^3}{3!}} x_i^3, \cdots \right) \cdot
             \left( 1, \sqrt{\frac{2 \gamma}{1!}} x_j, \sqrt{\frac{(2 \gamma)^2}{2!}} x_j^2,
             \sqrt{\frac{(2 \gamma)^3}{3!}} x_j^3, \cdots \right)^\text{T} \\
             &= e^{-\gamma (x_i^2 + x_j^2)} \left( 1^2 + \sqrt{\frac{2 \gamma}{1!}}^2 x_i x_j
             + \sqrt{\frac{(2 \gamma)^2}{2!}}^2 x_i^2 x_j^2 + \sqrt{\frac{(2 \gamma)^3}{3!}}^2
             x_i^3 x_j^3 + \cdots \right) \\
             &= e^{-\gamma (x_i^2 +  x_j^2)} \left( 1^2 + \frac{2 \gamma}{1!} x_i x_j
             + \frac{(2 \gamma)^2}{2!} x_i^2 x_j^2 + \frac{(2 \gamma)^3}{3!} x_i^3 x_j^3
             + \cdots \right) \\
             &= e^{-\gamma (x_i^2 +  x_j^2)} \cdot e^{2 \gamma x_i x_j}
             = e^{-\gamma (x_i^2 - 2 x_i x_j + x_j^2)} = e^{-\gamma (x_i - x_j)^2} = k(x_i, x_j)
        \end{align*}
        \item
        $ $
        \begin{enumerate}
            \item
            $ $
            \begin{table}[H]
                \centering
                \begin{tabularx}{\textwidth}{l|X|X}
                    \toprule
                    Property & $C$ small & $C$ large \\
                    \midrule
                    Margin & large & small \\
                    Complexity & The decision surface approximatly resembles a straight line (therefor rather simple) &
                    The decision surface curves along data clusters (therfor increasingly complex)\\
                    Train accuracy & For very small $C$ it seems that the accuracy decreases slightly & Depending on
                    $\gamma$ it appears that most of the time a higher accuracy can be achieved using large values for $C$ \\
                    \bottomrule
                \end{tabularx}
                \caption{Influence of the parameter $C$ on the decision function}
            \end{table}
            Concerning the accuracy: While in some cases a seemingly higher accuracy can be achieved usign large values for $C$
            there are also cases where neither very large nor very small values are desirable. In these cases moderate values
            should be chosen. Since these are solely visual observations it is hard to say that large / small values are always
            good or bad.

            \item
            $ $
            \begin{table}[H]
                \centering
                \begin{tabularx}{\textwidth}{l|X|X}
                    \toprule
                    Property & $\gamma$ small & $\gamma$ large \\
                    \midrule
                    Figure & A & B \\
                    Influence & small & high \\
                    \bottomrule
                \end{tabularx}
                \caption{Influence of the parameter $\gamma$ on the kernel and the decision function}
            \end{table}
        \end{enumerate}
    \end{enumerate}
\end{document}
